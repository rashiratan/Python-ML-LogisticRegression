{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1603a3e",
   "metadata": {},
   "source": [
    "# Assignment 12: Logistic Regression for Banknote Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b677b0f",
   "metadata": {},
   "source": [
    "Scenario: Imagine you are working for a financial institution developing automated systems to detect counterfeit banknotes. Data has been collected from images of genuine and forged banknote-like specimens. Features were extracted from these images using Wavelet Transform tools, resulting in four continuous numerical measurements. The goal is to build a model that can predict whether a banknote is genuine or forged based on these image-derived features.\n",
    "\n",
    "Dataset: Banknote Authentication Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3afdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries and modules\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b6c91",
   "metadata": {},
   "source": [
    "## Task 1: Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b12c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment starter code executed. Context Date: April 5, 2025\n",
      "\n",
      "--- Task 1: Data Loading and Preparation ---\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#executing rest of the starter code\n",
    "\n",
    "# Suppress potential convergence warnings for cleaner output (optional)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# --- Reference Date ---\n",
    "# Assignment context date: Saturday, April 5, 2025 (as per environment context)\n",
    "print(f\"Assignment starter code executed. Context Date: April 5, 2025\")\n",
    "\n",
    "# --- Task 1: Data Loading and Preparation ---\n",
    "print(\"\\n--- Task 1: Data Loading and Preparation ---\")\n",
    "\n",
    "# URL for the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
    "\n",
    "# Define column names\n",
    "column_names = ['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class']\n",
    "\n",
    "# Load data, specifying no header and comma separator\n",
    "try:\n",
    "    df = pd.read_csv(url, header=None, names=column_names, sep=',')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Exit or handle error appropriately in a real script\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93946dc8",
   "metadata": {},
   "source": [
    "Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "857f7fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Head:\n",
      "   Variance  Skewness  Curtosis  Entropy  Class\n",
      "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
      "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
      "2   3.86600   -2.6383    1.9242  0.10645      0\n",
      "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
      "4   0.32924   -4.4552    4.5718 -0.98880      0\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Variance  1372 non-null   float64\n",
      " 1   Skewness  1372 non-null   float64\n",
      " 2   Curtosis  1372 non-null   float64\n",
      " 3   Entropy   1372 non-null   float64\n",
      " 4   Class     1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n",
      "\n",
      "DataFrame Description:\n",
      "          Variance     Skewness     Curtosis      Entropy        Class\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
      "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
      "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
      "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
      "max       6.824800    12.951600    17.927400     2.449500     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Display basic info - Verify data loaded correctly\n",
    "print(\"\\nDataFrame Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\nDataFrame Description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80286e1e",
   "metadata": {},
   "source": [
    "Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "507d52aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X: (1372, 4)\n",
      "Shape of Y: (1372,)\n",
      "\n",
      "Describe X:\n",
      "           Variance     Skewness     Curtosis      Entropy\n",
      "count  1372.000000  1372.000000  1372.000000  1372.000000\n",
      "mean      0.433735     1.922353     1.397627    -1.191657\n",
      "std       2.842763     5.869047     4.310030     2.101013\n",
      "min      -7.042100   -13.773100    -5.286100    -8.548200\n",
      "25%      -1.773000    -1.708200    -1.574975    -2.413450\n",
      "50%       0.496180     2.319650     0.616630    -0.586650\n",
      "75%       2.821475     6.814625     3.179250     0.394810\n",
      "max       6.824800    12.951600    17.927400     2.449500\n",
      "Describe Y:\n",
      " count    1372.000000\n",
      "mean        0.444606\n",
      "std         0.497103\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare Features (X) and Target (Y) ---\n",
    "x = df[['Variance', 'Skewness', 'Curtosis', 'Entropy']] #-- features\n",
    "y = df['Class']                                         #-- target\n",
    "\n",
    "print(\"\\nShape of X:\", x.shape)\n",
    "print(\"Shape of Y:\", y.shape)\n",
    "\n",
    "#using pandas describe\n",
    "print(\"\\nDescribe X:\\n\", x.describe())\n",
    "print(\"Describe Y:\\n\", y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd3d5e",
   "metadata": {},
   "source": [
    "## Task 2: Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeb6bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Task 2: Train-Test Split ---\n",
      "Training set size: 1097\n",
      "Test set size: 275\n",
      "\n",
      "Forged vs. Genuine proportion in Train set:\n",
      " Class\n",
      "0    0.55515\n",
      "1    0.44485\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Forged vs. Genuine proportion in Test set:\n",
      " Class\n",
      "0    0.556364\n",
      "1    0.443636\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Task 2: Train-Test Split ---\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( #splitting data into train and test sets\n",
    "    x, y,\n",
    "    test_size=0.20,      # 25% for testing\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y     # Ensure class proportions are maintained in splits\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", x_train.shape[0])\n",
    "print(\"Test set size:\", x_test.shape[0])\n",
    "print(\"\\nForged vs. Genuine proportion in Train set:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nForged vs. Genuine proportion in Test set:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf23deb",
   "metadata": {},
   "source": [
    "## Task 3: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2189ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Task 3: Model Training ---\n",
      "\n",
      "Logistic Regression Model trained successfully on banknote authentication data.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Task 3: Model Training ---\")\n",
    "#standardize the training data\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(random_state=42) # Using defaults for now\n",
    "log_reg_model.fit(x_train, y_train) # Train ONLY on the training data\n",
    "\n",
    "print(\"\\nLogistic Regression Model trained successfully on banknote authentication data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abd0fb",
   "metadata": {},
   "source": [
    "## Task 4: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f929e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Task 4: Model Evaluation ---\n",
      "\n",
      "--- Predictions on Banknote Authentication Test Set ---\n",
      "First 5 Actual Labels:    [0 1 0 1 1]\n",
      "First 5 Predicted Labels: [0 1 0 1 1]\n",
      "\n",
      "First 5 Predicted Probabilities (P(Y=0), P(Y=1)):\n",
      "[[9.996e-01 4.000e-04]\n",
      " [3.360e-02 9.664e-01]\n",
      " [7.556e-01 2.444e-01]\n",
      " [3.560e-02 9.644e-01]\n",
      " [7.000e-03 9.930e-01]]\n",
      "\n",
      "--- Calculating the Accuracy Score\n",
      "Accuracy Score on Test Set: 0.97 (97.09%)\n",
      "\n",
      "--- Interpreting the Accuracy Score\n",
      "This means the model correctly predicted whether banknotes were forged or not for 97.09% of the banknotes in the unseen test data.\n",
      "\n",
      "--- Calculating the Precision and Recall Scores\n",
      "Precision Score: 0.94\n",
      "Recall Score: 1.00\n",
      "\n",
      "--- Interpreting the Precision and Recall Scores\n",
      "- Precision (0.94): When the model predicts a banknote is forged, it is correct 93.8% of the time.\n",
      "- Recall (1.00): The model correctly identifies 100.0% of all banknotes which were actually forged.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Task 4: Model Evaluation ---\")\n",
    "\n",
    "# Make predictions (y_pred) on the test data using the trained model\n",
    "y_pred_labels = log_reg_model.predict(x_test) #Predict Class Labels \n",
    "y_pred_proba = log_reg_model.predict_proba(x_test) #Predict Probabilities \n",
    "\n",
    "print(\"\\n--- Predictions on Banknote Authentication Test Set ---\")\n",
    "print(\"First 5 Actual Labels:   \", y_test.iloc[:5].values)\n",
    "print(\"First 5 Predicted Labels:\", y_pred_labels[:5])\n",
    "print(\"\\nFirst 5 Predicted Probabilities (P(Y=0), P(Y=1)):\")\n",
    "print(y_pred_proba[:5].round(4))\n",
    "\n",
    "\n",
    "# Calculate the accuracy_score by comparing y_pred to y_test\n",
    "print(\"\\n--- Calculating the Accuracy Score\")\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "# Print the accuracy score (formatted nicely)\n",
    "print(f\"Accuracy Score on Test Set: {accuracy:.2f} ({(accuracy*100):.2f}%)\")\n",
    "\n",
    "#Add a print statement interpreting the accuracy in context\n",
    "print(\"\\n--- Interpreting the Accuracy Score\")\n",
    "print(f\"This means the model correctly predicted whether banknotes were forged or not for {accuracy*100:.2f}% of the banknotes in the unseen test data.\")\n",
    "\n",
    "#Calculate the precision and recall scores\n",
    "print(\"\\n--- Calculating the Precision and Recall Scores\")\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision_score = tp/(tp+fp)\n",
    "recall_score = tp/(tp+fn)\n",
    "\n",
    "print(f\"Precision Score: {precision_score:.2f}\")\n",
    "print(f\"Recall Score: {recall_score:.2f}\")\n",
    "\n",
    "# Add a print statement interpreting these scores in context\n",
    "print(\"\\n--- Interpreting the Precision and Recall Scores\")\n",
    "print(f\"- Precision ({precision_score:.2f}): When the model predicts a banknote is forged, it is correct {(precision_score)*100:.1f}% of the time.\")\n",
    "print(f\"- Recall ({recall_score:.2f}): The model correctly identifies {recall_score*100:.1f}% of all banknotes which were actually forged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7685835",
   "metadata": {},
   "source": [
    "## Task 5: Coefficient Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39367e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Task 5: Coefficient Interpretation ---\n",
      "\n",
      "--- Logistic Regression Model Coefficients (Banknote Authentiction Data) ---\n",
      "--- Coefficients for Skewness:\n",
      "    Feature  Coefficient (Log-Odds)\n",
      "1  Skewness               -4.806524\n",
      "\n",
      "--- Coefficients for Entropy:\n",
      "   Feature  Coefficient (Log-Odds)\n",
      "3  Entropy                0.257966\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Task 5: Coefficient Interpretation ---\")\n",
    "\n",
    "# Extract coefficients from the trained model\n",
    "log_coefficients = log_reg_model.coef_[0]\n",
    "feature_names = x.columns\n",
    "coeffs_log_df = pd.DataFrame({'Feature': feature_names, 'Coefficient (Log-Odds)': log_coefficients})\n",
    "\n",
    "# Print the coefficients for 'Skewness' and 'Entropy'\n",
    "print(f\"\\n--- Logistic Regression Model Coefficients (Banknote Authentiction Data) ---\")\n",
    "print(f\"--- Coefficients for Skewness:\")\n",
    "print(coeffs_log_df[(coeffs_log_df['Feature'] == 'Skewness')])\n",
    "print(f\"\\n--- Coefficients for Entropy:\")\n",
    "print(coeffs_log_df[(coeffs_log_df['Feature'] == 'Entropy')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be182c0",
   "metadata": {},
   "source": [
    "## Task 6: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8713723",
   "metadata": {},
   "source": [
    "The logistic regression model achieved 97.09% accuracy, 94% precision, and 100% recall in banknote authentication, with a strong negative Skewness coefficient (-4.81) reducing forgery odds and a small positive Entropy coefficient (0.26) slightly increasing them. This reliable model excels at verification but could improve with advanced techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286b847",
   "metadata": {},
   "source": [
    "## Task 7: Code Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34434287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Task 7: Code Quality ---\n",
      "Ensure code is commented, uses meaningful variable names, and runs without errors.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Task 7: Code Quality ---\")\n",
    "print(\"Ensure code is commented, uses meaningful variable names, and runs without errors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
